<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Hard Code Art by suin3g</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <script src="javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1 class="header">Hard Code Art</h1>
        <p class="header">This is a project that is aimed at using Python and Neural Networks to understand art.  </p>

        <ul>
          <li class="download"><a class="buttons" href="https://github.com/suin3g/HardCodeArt/zipball/master">Download ZIP</a></li>
          <li class="download"><a class="buttons" href="https://github.com/suin3g/HardCodeArt/tarball/master">Download TAR</a></li>
          <li><a class="buttons github" href="https://github.com/suin3g/HardCodeArt">View On GitHub</a></li>
        </ul>

        <p class="header">This project is maintained by <a class="header name" href="https://github.com/suin3g">suin3g</a></p>


      </header>
      <section>
        <h1>
<a id="hardcodeart" class="anchor" href="#hardcodeart" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>HardCodeArt</em>
</h1>

<p><img src="https://github.com/suin3g/HardCodeArt/blob/master/examples/Disagreement.png?raw=true" alt="Graph with results"></p>

<p><img src="https://github.com/suin3g/HardCodeArt/blob/master/examples/HardCodeArt.jpg?raw=true" alt="Image of program"></p>

<h3>
<a id="background-and-theory" class="anchor" href="#background-and-theory" aria-hidden="true"><span class="octicon octicon-link"></span></a>Background and Theory:</h3>

<p>Sound is able to convey emotions that are more then just cultural. For music it seems most reasonable that this has everything to do with the frequencies that make it up. Using the Fourier Transform it is possible to map any function, including images, into the frequencies domain. My theory that the frequencies that make up images are responsible for the emotions that are conveyed by the image.</p>

<p><img src="https://github.com/suin3g/HardCodeArt/blob/master/examples/FFT.jpg?raw=true" alt="FFT of image"></p>

<p><em>FFT of image</em></p>

<h3>
<a id="model" class="anchor" href="#model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model:</h3>

<p>To test my theory I created a neural network using PyBrain's implementation, which I will train to recognize the adjectives people associate with art. The images will be transformed to the frequencies domain using Numpy's Fast Fourier Transform. This was used as the inputs to the Neural Network. The outputs are a set of adjectives. I narrowed down the adjectives to Sad, Happy, Serious, Whimsical, Peaceful, Intense, Angry, and Simple. Only images without recognizable objects in it will be used to insure that the emotions are caused by the colors and patterns not the objects.  </p>

<p><img src="https://github.com/suin3g/HardCodeArt/blob/master/examples/FFT2.jpg?raw=true" alt="Second FFT of image"></p>

<p><em>FFT of a seccond image</em></p>

<h3>
<a id="why-should-you-care" class="anchor" href="#why-should-you-care" aria-hidden="true"><span class="octicon octicon-link"></span></a>Why Should You Care:</h3>

<p>If the theory is right then it could be used to better understand how we interact with art. This could give insight into how we understand the world.</p>

<h3>
<a id="data-collection" class="anchor" href="#data-collection" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Collection:</h3>

<p>I had 15 volunteers examine 94 images. for each image I found the average and standard deviations of the number of disagreements between every pair of volunteers. This is used to compare how much each person agreed with each other. In the graph each point represents the average number of disagreements for one image and the error bars represent the standard deviation.</p>

<p><img src="https://github.com/suin3g/HardCodeArt/blob/master/examples/Human.png?raw=true" alt="Disagreement Between Humans"></p>

<p><em>Disagreement Between Humans</em></p>

<p>It is important to notice the large standard deviation this is because humans are very subjective and often do not agree with art. The most we can hope to achieve is an AI that is able to consistently chose emotions that when compared with the humans results in points within the error bars.      </p>

<h3>
<a id="data-compression" class="anchor" href="#data-compression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Compression:</h3>

<p>I am using a moving window approach to data collection. For each image I randomly choose part of the image. Either the whole image(blue), 1/4th of the image(red), or 1/16th of the image(red) is used. The part of the image used is randomized for each training epoch. </p>

<p><img src="https://github.com/suin3g/HardCodeArt/blob/master/examples/HardCodeArtWindow.jpg?raw=true" alt="Image of program with windows"></p>

<p><em>Data Collection Windows</em></p>

<p>One of the major issues is that the amount of data in an image is huge. The Fourier Transform does not change the amount of data. Though if one takes the absolute value of the Fourier Transform of an image it exhibits rotational symmetry.</p>

<p><img src="https://github.com/suin3g/HardCodeArt/blob/master/examples/FFT3.png?raw=true" alt="FFT of image with rotational symmetry"></p>

<p><em>FFT of image with rotational symmetry</em></p>

<p>I used this fact and only considered half the FFT. I then considered only eight windows and took the advantage value of the FFT within these windows. Each Color is considered by itself. I also considered the standard deviations within each of these windows. In all this leads to 48 inputs.</p>

<p><img src="https://github.com/suin3g/HardCodeArt/blob/master/examples/FFT3edit.png?raw=true" alt="FFT of image with eight key windows">  </p>

<p><em>FFT of image with eight key windows</em></p>

<p>There is a inner layer with 16 levels and the output layer has the 8 emotions. </p>

<h3>
<a id="results" class="anchor" href="#results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results:</h3>

<p>To see if the training worked we must first look at an untrained network. This graph is like the one shown above with the results from an untrained network added in red. Each red point represents the average disagreement between the emotions the AI chose and each human. Because the AI is untrained it is basically making random guesses. </p>

<p><img src="https://github.com/suin3g/HardCodeArt/blob/master/examples/Random.png?raw=true" alt="Disagreement Between Humans and Random"></p>

<p><em>Random</em></p>

<p>Two important numbers to notice are the number of points outside the standard deviation and the number of points above the human mean. 88% of the points where above above the human mean, and 52% of the points were outside the standard deviation for this untrained AI.</p>

<p>The Next Graph shows the results after the network was trained.</p>

<p><img src="https://github.com/suin3g/HardCodeArt/blob/master/examples/AI.png?raw=true" alt="Disagreement Between Humans and Trained AI"></p>

<p><em>Trained AI</em></p>

<p>This is much better then random. Only 1% of the points are outside the standard deviation and 39% are above the human mean. This means that the computer is making choice similar to those that a human would. The first ten images were not used in training and act as a validation set. The fact that for these ten images the mean disparagement is still within the standard deviation shows that the network was not over trained, and seems to be working for more then just those images trained on. From this data set one would not be able to tell if this were done by a human or a computer. That is as good as is possible and I consider this a huge success.  </p>

<h3>
<a id="using-software" class="anchor" href="#using-software" aria-hidden="true"><span class="octicon octicon-link"></span></a>Using software:</h3>

<p>After downloading code you must add the images you would like to use to a file named "images" in the project folder. I did not include the images I used because I do not own rights to them.</p>
      </section>
      <footer>
        <p><small>Hosted on <a href="https://pages.github.com">GitHub Pages</a> using the Dinky theme</small></p>
      </footer>
    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
		
  </body>
</html>
