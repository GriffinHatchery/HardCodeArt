{"name":"Hard Code Art","tagline":"This is a project that is aimed at using Python and Neural Networks to understand art.  ","body":"![Image of program](https://github.com/suin3g/HardCodeArt/blob/master/examples/HardCodeArt.jpg?raw=true)\r\n\r\n_HardCodeArt_\r\n\r\n### Background and Theory:\r\nSound is able to convey emotions that are more then just cultural. For music it seems most reasonable that this has everything to \u000Bdo with the frequencies that make it up. Using the Fourier Transform it is possible to map any function, including images,\u000B into the frequencies domain. My theory that the frequencies that make up images are responsible for the emotions that are conveyed by the image.\r\n\r\n![FFT of image](https://github.com/suin3g/HardCodeArt/blob/master/examples/FFT.jpg?raw=true)\r\n\r\n_FFT of image_\r\n\r\n### Model:\r\nTo test my theory I created a neural network using PyBrain's implementation, which I will train to recognize the adjectives people associate with art. The images will be transformed to the frequencies domain using Numpy's Fast Fourier Transform. This will be used as the inputs to the Neural Network. The outputs will be a set of adjectives. I narrowed down the adjectives to Sad, Happy, Serious, Whimsical, Peaceful, Intense, Angry, and Simple. Only images without recognizable objects in it will be used to insure that the emotions are caused by the colors and patterns not the objects.  \r\n\r\n![Second FFT of image](https://github.com/suin3g/HardCodeArt/blob/master/examples/FFT2.jpg?raw=true)\r\n\r\n_FFT of a seccond image_\r\n\r\n### Why Should You Care:\r\nIf the theory is right then it could be used to better understand how we interact with art. This could give insight into how we understand the world.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}